# -*- coding: utf-8 -*-
"""Main_ARM_Hackathon.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1agGM-0H-GOzbVMFiXyJhHaYPMPbkh8Rt
"""

!nvidia-smi

#Mounting drive and adding dataset to drive. Add same path here.

from google.colab import drive
drive.mount('/content/gdrive')

!cp -r /content/gdrive/MyDrive/ARM_Hackathon/dataset /content/

#To check if the files are mounted after mounting the drive. Folders will not be visible

!ls /content/gdrive/MyDrive/ARM_Hackathon

#To install the requirements.

!pip install ultralytics

#Model Training. Add path name, model name, epochs and resolution correctly.

!yolo task=detect mode=train \
data=/content/dataset/images/data.yaml \
model=yolov8n.pt \
epochs=100 \
imgsz=416 \
batch=16 \
lr0=0.001 \
lrf=0.01 \
cos_lr=True \
weight_decay=0.001 \
patience=15 \
hsv_h=0.015 \
hsv_s=0.7 \
hsv_v=0.4 \
translate=0.1 \
scale=0.4 \
fliplr=0.5 \
mosaic=1.0 \
close_mosaic=20 \
dropout=0.1 \
name=final_smooth_training3

#Testing with images

from ultralytics import YOLO
import cv2
import os
import numpy as np

# Load trained model
model = YOLO("/content/runs/detect/final_smooth_training3/weights/best.pt")

source_folder = "/content/dataset/images/test/images"
output_folder = "/content/runs/detect/final_smooth_training3/fn_reduced_output_images"
os.makedirs(output_folder, exist_ok=True)

# üîß FN-Optimized PARAMETERS
CONF_THRESHOLD = 0.3          # Lowered for higher recall
IOU_THRESHOLD = 0.5           # Slightly relaxed
MIN_AREA_RATIO = 0.0001       # Allow smaller detections
MAX_AREA_RATIO = 0.35         # Allow slightly larger detections
ROAD_REGION_Y_MIN = 0.25      # Relax road constraint

for img_name in os.listdir(source_folder):
    img_path = os.path.join(source_folder, img_name)
    img = cv2.imread(img_path)

    if img is None:
        continue

    h, w, _ = img.shape
    img_area = h * w

    # üî• TTA Enabled (augment=True)
    results = model.predict(
        img,
        conf=CONF_THRESHOLD,
        iou=IOU_THRESHOLD,
        classes=[3, 4, 5],
        augment=True,
        verbose=False
    )

    boxes = results[0].boxes

    for box in boxes:
        x1, y1, x2, y2 = map(int, box.xyxy[0])
        conf = float(box.conf[0])
        cls_id = int(box.cls[0])

        box_area = (x2 - x1) * (y2 - y1)
        box_area_ratio = box_area / img_area
        center_y = (y1 + y2) / 2 / h

        # üîπ Relaxed Road Constraint
        if center_y < ROAD_REGION_Y_MIN:
            continue

        # üîπ Relaxed Size Filtering
        if box_area_ratio < MIN_AREA_RATIO or box_area_ratio > MAX_AREA_RATIO:
            continue

        label = f"{model.names[cls_id]} {conf:.2f}"
        cv2.rectangle(img, (x1, y1), (x2, y2), (0, 255, 0), 2)
        cv2.putText(img, label, (x1, y1 - 5),
                    cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)

    cv2.imwrite(os.path.join(output_folder, img_name), img)

print("False-negative reduced images saved.")

#Randomly seeing the mAp on the test images. You can change the number of images you want to see.

import glob
from IPython.display import Image, display

for image_path in glob.glob(f'/content/runs/detect/final_smooth_training3/fn_reduced_output_images/*.jpg')[:20]:
    display(Image(filename=image_path, height=400))
    print('\n')

from ultralytics import YOLO
import cv2
import os

model = YOLO("/content/runs/detect/final_smooth_training3/weights/best.pt")

root_video_folder = "/content/dataset/videos_without_audio"
output_root = "/content/runs/detect/final_smooth_training3/fn_reduced_video_output"
os.makedirs(output_root, exist_ok=True)

BASE_CONF = 0.3
IOU_THRESHOLD = 0.5
MIN_AREA_RATIO = 0.0001
MAX_AREA_RATIO = 0.35
ROAD_REGION_Y_MIN = 0.25

# üîÅ Loop through all main folders
for main_folder in os.listdir(root_video_folder):

    main_path = os.path.join(root_video_folder, main_folder)

    if not os.path.isdir(main_path):
        continue

    # üîÅ Loop inside subfolders
    for sub_folder in os.listdir(main_path):

        sub_path = os.path.join(main_path, sub_folder)

        if not os.path.isdir(sub_path):
            continue

        print(f"\nProcessing folder: {sub_path}")

        video_list = sorted([v for v in os.listdir(sub_path) if v.endswith(".mp4")])[:10]

        print(f"Total selected videos: {len(video_list)}")

        for video_name in video_list:

            print(f"Processing video: {video_name}")

            video_path = os.path.join(sub_path, video_name)
            cap = cv2.VideoCapture(video_path)

            if not cap.isOpened():
                continue

            width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
            height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
            fps = int(cap.get(cv2.CAP_PROP_FPS))

            output_path = os.path.join(output_root, video_name)

            out = cv2.VideoWriter(
                output_path,
                cv2.VideoWriter_fourcc(*'mp4v'),
                fps,
                (width, height)
            )

            while True:
                ret, frame = cap.read()
                if not ret:
                    break

                img_area = width * height

                results = model.predict(
                    frame,
                    conf=BASE_CONF,
                    iou=IOU_THRESHOLD,
                    augment=True,   # keep True in Colab
                    verbose=False
                )

                boxes = results[0].boxes

                for box in boxes:
                    x1, y1, x2, y2 = map(int, box.xyxy[0])
                    conf = float(box.conf[0])
                    cls_id = int(box.cls[0])

                    box_area = (x2 - x1) * (y2 - y1)
                    box_area_ratio = box_area / img_area
                    center_y = (y1 + y2) / 2 / height

                    if center_y < ROAD_REGION_Y_MIN:
                        continue

                    if box_area_ratio < MIN_AREA_RATIO or box_area_ratio > MAX_AREA_RATIO:
                        continue

                    label = f"{model.names[cls_id]} {conf:.2f}"
                    cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)
                    cv2.putText(frame, label, (x1, y1 - 5),
                                cv2.FONT_HERSHEY_SIMPLEX, 0.5,
                                (0, 255, 0), 2)

                out.write(frame)

            cap.release()
            out.release()

print("All folders processed successfully.")

import glob
from IPython.display import Video, display
import random

video_files = glob.glob('/content/runs/detect/final_smooth_training3/fn_reduced_video_output/*.mp4')

# Make sure we don't exceed available videos
num_videos = min(5, len(video_files))

# Pick 5 random videos
selected_videos = random.sample(video_files, num_videos)

for video_path in selected_videos:
    print("Showing:", video_path)
    display(Video(video_path, embed=True))

from ultralytics import YOLO

model = YOLO("/content/runs/detect/final_smooth_training3/weights/best.pt")

metrics = model.val(
    data="/content/dataset/images/data.yaml",
    split="test",
    conf=0.25,
    iou=0.6
)

print(metrics)
print("mAP50:", metrics.box.map50)
print("mAP50-95:", metrics.box.map)
print("Precision:", metrics.box.p)
print("Recall:", metrics.box.r)

from ultralytics import YOLO

model = YOLO("/content/runs/detect/final_smooth_training/weights/best.pt")

model.export(
    format="onnx",
    opset=12,
    simplify=True,
    dynamic=True
)

from ultralytics import YOLO

model = YOLO("/content/runs/detect/final_smooth_training/weights/best.pt")

model.export(
    format="onnx",
    opset=12,
    simplify=True,
    dynamic=True,
    half=True
)

!cp -r /content/runs /content/gdrive/MyDrive/

